services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: fraudguard-zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: fraudguard-kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: fraudguard-zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://fraudguard-kafka:9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  producer:
    build: ./simulation
    container_name: fraudguard-producer
    depends_on:
      - kafka
    volumes:
      - ./data:/opt/data         
    entrypoint: >
      /bin/bash -c "python /opt/app/producer.py"

  predictions:
    build: ./Streaming
    container_name: fraudguard-predictions
    depends_on:
      - kafka
    volumes:
      - ./Streaming:/opt/app
      - ./fraud_model.pkl:/opt/app/fraud_model.pkl
      - ./Streaming/log4j2.properties:/opt/spark/conf/log4j2.properties
    environment:
      - SPARK_SUBMIT_OPTS=-Dlog4j.configurationFile=file:/opt/spark/conf/log4j2.properties
    entrypoint: >
      /bin/bash -c "spark-submit /opt/app/stream_app.py"

  websocket_server:
    build: ./websocket # Directory for your server code
    container_name: fraudguard-websocket
    depends_on:
      - kafka
      - predictions # Depends on Spark starting to produce metrics
    ports:
      - "5000:5000" # Port for the WebSocket server
    environment:
      KAFKA_BROKER: kafka:9092
      KAFKA_TOPIC: realtime_fraud_metrics
  
  frontend:
    build: ./frontend
    container_name: fraudguard-frontend
    ports:
      - "8080:80" # Map host port 8080 to container port 80
    depends_on:
      - websocket_server # Ensure WebSocket server is running first